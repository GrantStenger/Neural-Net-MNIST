{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a3647bee-6c37-43ce-b70e-73b0ac767a37"
    }
   },
   "source": [
    "# Intro to Keras: Neural Networks for Digit Classification\n",
    "Online lesson link: http://caisplusplus.usc.edu/blog/curriculum/lesson5\n",
    "\n",
    "#### Relevant guides:\n",
    "* Getting started with Keras: https://keras.io/\n",
    "* Sequential model guide: https://keras.io/getting-started/sequential-model-guide/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "nbpresent": {
     "id": "aa21eec0-d9e9-4575-8cec-408d8f044b20"
    }
   },
   "outputs": [],
   "source": [
    "# Import MNIST dataset from Keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "(train_x, train_y), (test_x, test_y) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "nbpresent": {
     "id": "b04508f5-7038-4d57-a3ad-a8e1dd3e172e"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape is (60000, 28, 28)\n",
      "Input type is <class 'numpy.ndarray'>\n",
      "Labels:\n",
      "[5 0 4 ..., 5 6 8]\n",
      "Labels shape is(60000,)\n",
      "Labels type is <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Data exploration\n",
    "\n",
    "print(\"Inputs shape is \" + str(train_x.shape)) # 60,000 samples, each image: 28 x 28 pixels\n",
    "print(\"Input type is \" + str(type(train_x)))\n",
    "print(\"Labels:\")\n",
    "print(train_y)\n",
    "print(\"Labels shape is\" + str(train_y.shape))\n",
    "print(\"Labels type is \" + str(type(train_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "4f9fadce-17a5-45d3-abeb-4c09ff57cfa7"
    }
   },
   "outputs": [],
   "source": [
    "# Matplotlib: Data visualization library\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "nbpresent": {
     "id": "572a96a1-19cb-45e3-9763-acfc3d87dc7f"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEBThB4L6H3M9EtsJQgBAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1229c1eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the input samples\n",
    "\n",
    "sample_num = 98\n",
    "\n",
    "plt.imshow(train_x[sample_num], cmap=plt.get_cmap('gray'))\n",
    "print(train_y[sample_num])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing the Data: \n",
    "* Flatten the 28 x 28 images into 784-dimensional vectors\n",
    "* Normalize the pixel values from 0-255 to 0-1\n",
    "* Categorize the outputs into 10-dimensional \"one-hot\" vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "f8dd8606-82f9-4d0c-a62b-45beb371eddc"
    }
   },
   "outputs": [],
   "source": [
    "# flatten 28*28 images to a 784 vector for each image\n",
    "\n",
    "num_pixels = train_x.shape[1] * train_x.shape[2] # 28 * 28 = 784\n",
    "train_x_flattened = train_x.reshape(train_x.shape[0], num_pixels).astype('float32') # new shape: 60,000 x 784\n",
    "test_x_flattened = test_x.reshape(test_x.shape[0], num_pixels).astype('float32') # new shape: 10,000 x 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "23cd5489-7e90-47a1-aba3-2a802d1075ac"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize pixel values to between 0-1\n",
    "train_x_flattened = train_x_flattened / 255.\n",
    "test_x_flattened = test_x_flattened / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "nbpresent": {
     "id": "e11182b1-7e19-4c34-be1e-b1c71179f014"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "# Use Keras to categorize the outputs (\"one-hot\" vectors)\n",
    "train_y_categorical = keras.utils.to_categorical(train_y, num_classes=10)\n",
    "test_y_categorical = keras.utils.to_categorical(test_y, num_classes=10)\n",
    "\n",
    "# let's see result of categorizing the outputs\n",
    "print(test_y_categorical[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating our Neural Network Model\n",
    "1. Initialize the model, add desired layers\n",
    "2. Compile the model to get ready for training\n",
    "3. Set up the callbacks to track the model training/improvement\n",
    "4. Fit the model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "81b9fc81-511c-4d2d-be23-883d0009bc74"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Initialize simple neural network model\n",
    "model = Sequential()\n",
    "\n",
    "# TODO: add layers to the model\n",
    "# Hidden layer 1: 500 neurons, 'relu' activation\n",
    "model.add(Dense(units=500, input_dim=784))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Hidden layer 2: 250 neurons, 'relu' activation\n",
    "model.add(Dense(units=250))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Hidden layer 3: 250 neurons, 'relu' activation\n",
    "model.add(Dense(units=250))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Hidden layer 4: 250 neurons, 'relu' activation\n",
    "model.add(Dense(units=250))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Output layer: 10 neurons (one for each class), softmax activation\n",
    "model.add(Dense(units=10))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "bf842b6a-20db-42f4-9333-b1e30857e725"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the model, get ready to train\n",
    "\n",
    "# TODO: compile the model\n",
    "    # Loss: categorical cross-entropy\n",
    "    # Optimizer: stochastic gradient descent (SGD)\n",
    "    # Additional metrics: Accuracy\n",
    "    \n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='sgd',\n",
    "             metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                2510      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 645,760\n",
      "Trainable params: 645,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callback tools:\n",
    "* **TQDM**: progress bar library\n",
    "* **Tensorboard**: built-in tool to plot model loss, accuracy, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "nbpresent": {
     "id": "cadc9d02-6798-4902-b97f-16591fe7ed58"
    }
   },
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "from keras_tqdm import TQDMNotebookCallback # TQDM: progress bars\n",
    "from keras.callbacks import TensorBoard # Tensorboard: training plots\n",
    "    \n",
    "# Clear any existing Tensorboard logs\n",
    "import shutil\n",
    "shutil.rmtree('./logs', ignore_errors=True)\n",
    "\n",
    "# Set up callback links to refer back to during training\n",
    "tensorboard = TensorBoard()\n",
    "callbacks_list = [TQDMNotebookCallback(), tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "nbpresent": {
     "id": "2fbdd2f4-e1eb-4bd5-aef4-5869948e4b89"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e29f759cfa4a65a8727d49c3e2d0de"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1ff27ea522429a8b41cccca245abf6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009f5b08fd124ae28cd90514c54f2e42"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28edc122199a4a228a3e80bc487743ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5789e8ad9c4f1faf45386812935ad8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c17bdc175b4aada9404569338c9b76"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2fa124ed2264edea4d09b07c4395b68"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d49a67c4c14f389ac192ef42e97b80"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c5003820a04bbd92075308a268b519"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65fa63bbb384ab5ac241a80ec57ce45"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e66f9df2c874140bb65936eb83df2c3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1234f8208>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "\n",
    "# Validation split: reserve some of our training data to use as \"validation\" data\n",
    "    # Won't train on validation data -- check validation loss to look for overfitting\n",
    "    \n",
    "# Pass in our callbacks to track training progress\n",
    "\n",
    "# TODO: train the model\n",
    "    # Number of epochs: 5\n",
    "    # Batch size: 32\n",
    "    # Validation split: 0.1\n",
    "    # Verbose setting: use TQDM progress bars\n",
    "    \n",
    "model.fit(train_x_flattened, train_y_categorical,\n",
    "         epochs=10,\n",
    "         batch_size=32,\n",
    "         validation_split=0.1,\n",
    "         verbose=0,\n",
    "         callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To launch Tensorboard after training:**\n",
    "* Type in command line: `tensorboard --logdir ./logs`\n",
    "* Open in browser: `http://localhost:6006`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "nbpresent": {
     "id": "0864543a-2392-4ae5-bbdd-375e934184f4"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 62us/step\n",
      "Accuracy is 0.9742\n"
     ]
    }
   ],
   "source": [
    "# Evaluate trained model on test data\n",
    "\n",
    "# returns final test loss & test accuracy\n",
    "loss_and_metrics = model.evaluate(test_x_flattened, test_y_categorical, batch_size=128)\n",
    "\n",
    "print(\"Accuracy is \" + str(loss_and_metrics[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly: Make sure the our neural network's predictions match up with the actual images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "nbpresent": {
     "id": "3cdfe0ff-f08a-4ded-af33-c091211b22a7"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.74387150e-06   5.84403097e-07   3.71911447e-04   9.78760654e-04\n",
      "    2.23301715e-08   1.17319780e-06   2.05665814e-11   9.98560607e-01\n",
      "    1.53827859e-05   6.78315264e-05]]\n",
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nosJxHysAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11dcad4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample_num = 0 # which test sample to look at\n",
    "\n",
    "# Predicted class\n",
    "test_sample = np.expand_dims(test_x_flattened[sample_num], axis=0) # pick out a one-sample \"batch\" to feed into model\n",
    "predicted_scores = model.predict(test_sample) # outputted probabilities vector\n",
    "print(predicted_scores) # print predicted scores\n",
    "\n",
    "predicted_class = np.argmax(predicted_scores) # pick the class with highest probability --> final prediction\n",
    "print(predicted_class) # print predicted classification\n",
    "\n",
    "# Show actual input image\n",
    "plt.imshow(test_x[sample_num], cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
